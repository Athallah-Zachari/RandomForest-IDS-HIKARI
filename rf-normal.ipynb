{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12595413,"sourceType":"datasetVersion","datasetId":7955384}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Hapus semua library yang berpotensi konflik sekaligus\n!pip uninstall scikit-learn imbalanced-learn category_encoders -y\n\n# Install kembali semua library yang dibutuhkan\n!pip install scikit-learn imbalanced-learn category_encoders\n\n#import model from local /kdn/docs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Import Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np \n\ndf = pd.read_csv('/kaggle/input/hikari-zenkii/ALLFLOWMETER_HIKARI2021.csv')\n\n# Menghapus kolom metadata\ntoDrop = ['uid', 'Unnamed: 0', 'Unnamed: 0.1','fwd_URG_flag_count', 'bwd_URG_flag_count']\ndf = df.drop(columns=toDrop)\n\ntarget2 = ['Background', 'Probing', 'XMRIGCC CryptoMiner']\ntarget3 = ['Background', 'XMRIGCC CryptoMiner']\ntarget4 = ['Background', 'Probing']\n\ndf = df[~df['traffic_category'].isin(target1)].copy()\n\nprint(df['traffic_category'].value_counts())\nprint(df.shape)\nprint(df.columns.tolist())\nprint(df.head(10))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Data Analysis (Cek Kriteria)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_columns', None)\n\nfeatures_id = [\n    'fwd_data_pkts_tot',\n    'fwd_iat.tot',\n    'flow_pkts_payload.tot',\n    'fwd_pkts_payload.tot',\n    'bwd_pkts_payload.tot',\n    'flow_duration',\n    'flow_iat.tot',\n    'fwd_iat.max',\n    'bwd_iat.tot',\n    'fwd_subflow_pkts',\n    'bwd_subflow_pkts',\n    'fwd_subflow_bytes',\n    'bwd_subflow_bytes',\n    'down_up_ratio'\n]\n\nfeatures = [        \n    'flow_FIN_flag_count',\n    'flow_SYN_flag_count',\n    'flow_ACK_flag_count',\n    'flow_RST_flag_count',\n    'fwd_PSH_flag_count',\n    'bwd_PSH_flag_count',\n    'flow_CWR_flag_count',\n    'flow_ECE_flag_count'\n]\n\nstatistik = df.groupby('traffic_category')[ppt].agg(\n    # ['min', 'max', 'mean', 'median', 'std', 'count', 'nunique']\n    ['count', 'nunique']\n)\n\nprint(\"--- Statistik Deskriptif Fitur Teratas untuk Setiap Jenis Serangan ---\")\nprint(statistik)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Asumsikan 'df' adalah DataFrame lengkap Anda\n\n# 1. Definisikan fitur dan kategori serangan yang ingin dibandingkan\nfeatures = [ \n    'flow_duration'\n]\n\nfor feature in features:\n    plt.figure(figsize=(12, 7))\n    sns.barplot(\n        x='traffic_category', \n        y=feature, \n        data=df\n    )\n    plt.title(f'Persebaran Fitur \"{feature}\" per Jenis Serangan', fontsize=16)\n    plt.xlabel('Jenis Serangan', fontsize=12)\n    plt.ylabel(f'Nilai {feature}', fontsize=12)\n    plt.xticks(rotation=45)\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cek tipedata 'object' pada fitur yang ada\ndf.select_dtypes(include='object').dtypes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Split Data","metadata":{}},{"cell_type":"code","source":"# Memisahkan fitur - fitur (x) dengan Label (y) \nx = df.select_dtypes(include=['number']).drop(columns=['Label'], errors='ignore')\ny = df['Label']\n\nprint(x.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#Split Data \nxTrain, xTest, yTrain, yTest = train_test_split( \n    x, y, \n    test_size = 0.2,\n    stratify=y,\n    random_state=42 \n)\n\nprint(\"Dimensi DATA TRAIN (xTrain): \")\nprint(xTrain.shape)\nprint(\"Dimensi DATA TES (xTest): \")\nprint(xTest.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Presentase persebaran jenis kelas (Normal/Attack)\nprint(yTrain.value_counts(normalize=True)*100)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Selection (Permutation)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score\nfrom tqdm.notebook import tqdm # Progress bar\n\n# (Baseline)\nprint(\"Melatih model baseline...\")\nmodel = RandomForestClassifier(random_state=42, n_jobs=-1)\nmodel.fit(xTrain, yTrain)\n\n# Performa Baseline\nyPred_baseline = model.predict(xTest)\nbaseline_score = f1_score(yTest, yPred_baseline)\nprint(f\"Skor F1 Baseline: {baseline_score:.4f}\")\n\n# Permutasi untuk Setiap Fitur\nimportances = {}\n# Progress Bar\nfor col in tqdm(xTrain.columns, desc=\"Menghitung Importance Fitur\"):\n    # Buat salinan data tes untuk diacak\n    xTest_shuffled = xTest.copy()\n    \n    # Acak nilai HANYA di satu kolom (fitur)\n    np.random.shuffle(xTest_shuffled[col].values)\n    \n    # Lakukan prediksi dengan data yang sudah diacak\n    yPred_shuffled = model.predict(xTest_shuffled)\n    \n    # Hitung skor baru\n    shuffled_score = f1_score(yTest, yPred_shuffled)\n    \n    # Skor importance adalah selisihnya\n    importances[col] = baseline_score - shuffled_score\n\n# Peringkat fitur dengan skor tertinggi\nprint(\"\\n--- Hasil Permutation Feature Importance ---\")\nimportance_df = pd.DataFrame(\n    list(importances.items()), \n    columns=['Fitur', 'Importance']\n).sort_values('Importance', ascending=False)\n\nprint(importance_df.head(15)) \n\n# --- MEMBUAT DATAFRAME BARU ---\n\n# Tentukan jumlah fitur teratas yang ingin Anda simpan\ntop_features = 15 # Anda bisa mengubah angka ini\n\n# Ambil daftar nama dari N fitur teratas\nselected_feature = importance_df['Fitur'].head(top_features).to_list()\n\n# Buat DataFrame baru hanya dengan fitur-fitur terpilih\nxTrain_selected = xTrain[selected_feature]\nxTest_selected = xTest[selected_feature]\n\n# --- Verifikasi ---\nprint(f\"\\nBerhasil memilih {top_features} fitur teratas.\")\nprint(f\"Bentuk xTrain baru: {xTrain_selected.shape}\")\nprint(f\"Bentuk xTest baru: {xTest_selected.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Seleksi fitur manual\n\nfeatures = [\n    'idle.tot',\n    'active.tot',\n    'flow_pkts_payload.tot',\n    'flow_pkts_payload.avg',\n    'fwd_pkts_payload.tot',\n    'fwd_pkts_payload.avg',\n    'bwd_pkts_payload.tot',\n    'bwd_pkts_payload.avg',\n    'flow_duration',\n    'fwd_subflow_pkts',\n    'bwd_subflow_pkts',\n    'fwd_subflow_bytes',\n    'bwd_subflow_bytes'\n]\n\n#konsisten muncul di permutasi\nfeatures2 = [\n    'bwd_header_size_tot',\n    'bwd_pkts_payload.tot',\n    'fwd_pkts_payload.max',\n    'flow_pkts_payload.tot',\n    'bwd_pkts_tot',\n    'fwd_subflow_bytes',\n    'fwd_data_pkts_tot',\n    'fwd_iat.tot',\n    'bwd_iat.tot',\n    'flow_RST_flag_count',\n    'flow_duration',\n    'idle.tot',\n    'active.tot'\n]\n\n#class x\nfeatures3 = [\n    'idle.tot',\n    'active.tot',\n    'flow_pkts_payload.tot',\n    'flow_pkts_payload.avg',\n    'fwd_pkts_payload.tot',\n    'fwd_pkts_payload.avg',\n    'bwd_pkts_payload.tot',\n    'bwd_pkts_payload.avg',\n    'flow_duration',\n    'fwd_subflow_pkts',\n    'bwd_subflow_pkts',\n    'fwd_subflow_bytes',\n    'bwd_subflow_bytes',\n    'responh_2',\n    'responh_3',\n    'responh_4'\n]\n\n# Buat DataFrame baru hanya dengan fitur-fitur terpilih\nxTrain_selected = xTrain[features3]\nxTest_selected = xTest[features3]\n\nxTrain_selected.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Export DF dengan fitur terpilih\nimport pandas as pd\n\ndf_fitur = pd.DataFrame(selected_feature, columns=['Nama Fitur Pilihan'])\ndf_fitur.to_csv('feature_permutasi.csv', index=False)\n\nprint(f\"File '{'feature_permutasi.csv'}' berhasil dibuat!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Scaling","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n#Scaling Data\nscaler = StandardScaler()\nxTrain_scaled = scaler.fit_transform(xTrain_selected)\nxTest_scaled = scaler.transform(xTest_selected)\n\nprint(xTrain_scaled.shape)\nprint(xTrain_scaled)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\n\n# Simpan objek 'scaler' \n# joblib.dump(scaler, 'scaler.joblib')\n# xTest_selected.to_csv('xTest_selected.csv', index=False)\n# xTrain_selected.to_csv('xTrain_selected.csv', index=False)\n# joblib.dump(rf_model, 'rf_model_3.joblib')\n# joblib.dump(xTest_selected, 'xTest_selected.joblib')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Hybrid-sampling (SMOTE-ENN)","metadata":{}},{"cell_type":"code","source":"from imblearn.combine import SMOTEENN\n\nsmote_enn = SMOTEENN(random_state=42, n_jobs=-1)\nprint(\"Memulai resampling SMOTEEENN...\")\nxTrain_resampled, yTrain_resampled = smote_enn.fit_resample(xTrain_scaled, yTrain)\nprint(\"Resampling selesai!!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cek presentase persebaran setelah prose shybrid-sampling\nprint(yTrain.value_counts(normalize=True)*100)\nprint(yTrain_resampled.value_counts(normalize=True)*100)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"yTest_category = df.loc[yTest.index, 'traffic_category']\n\n# yTest_category_label = pd.concat([\n#     xTest_selected.reset_index(drop=True),\n#     yTest_category[['traffic_category']].reset_index(drop=True)\n# ], axis=1)\n\nyTest_category_label = pd.concat([\n    xTest_selected,\n    yTest_category\n], axis=1)\n\nyTest_category_label.head\nprint(yTest_category_label.shape)\n\nyTest_category_label.to_csv('yTest_category.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xTrain.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training Model (Random Forest)","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf_model = RandomForestClassifier(\n    criterion='entropy',\n    n_estimators=200,\n    max_depth=30,\n    min_samples_split=2,\n    min_samples_leaf=10,\n    max_features='sqrt',\n    bootstrap=True,\n    random_state=42,\n    n_jobs=-1,\n    class_weight= 'balanced',\n    # class_weight= {0:1, 1:10},\n    verbose=2\n  )\n\nrf_model.fit(xTrain_resampled, yTrain_resampled) #dengan oversampling\n# rf_model.fit(xTrain_scaled, yTrain) #tanpa oversampling","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluasi Model (Random Forest)","metadata":{}},{"cell_type":"code","source":"import joblib\n\nrf_model_all = joblib.load('/kaggle/input/rf-models/rf_model_1.joblib') \nrf_model_2 = joblib.load('/kaggle/input/rf-models/rf_model_2.joblib') \nrf_model_3 = joblib.load('/kaggle/input/rf-models/rf_model_3.joblib') ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#KLASIFIKASI BINER\n\nfrom sklearn.metrics import (\n    classification_report, \n    confusion_matrix, \n    roc_auc_score, \n    roc_curve, \n    accuracy_score,\n    precision_recall_curve\n)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\nyPred_prob = rf_model.predict_proba(xTest_scaled)[:, 1]\n\nprecision, recall, thresholds = precision_recall_curve(yTest, yPred_prob)\n# Hitung f1-score untuk setiap threshold\nf1_scores = np.divide(2 * recall * precision, recall + precision,\n                      out=np.zeros_like(recall), where=(recall+precision) != 0)\n\n# threshold untuk F1-score tertinggi\nbest_threshold = thresholds[np.argmax(f1_scores)]\nprint(f\"Threshold optimal yang ditemukan: {best_threshold:.4f}\")\n\n# Setting threshold\nyPred_binary = (yPred_prob > best_threshold).astype(int)\n\n# Prediksi\nprint(\"\\nEvaluasi model dengan threshold optimal:\")\nprint(classification_report(yTest, yPred_binary, target_names=['Normal(0)', 'Anomali(1)']))\n\nprint(\"\\nConfusion Matrix:\")\ncm = confusion_matrix(yTest, yPred_binary)\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['Normal(0)', 'Anomali(1)'],\n            yticklabels=['Normal(0)', 'Anomali(1)'])\nplt.title('Confusion Matrix', fontsize=16)\nplt.ylabel('Label Aktual')\nplt.xlabel('Label Prediksi')\nplt.show()\n\n# ROC AUC \nauc_score = roc_auc_score(yTest, yPred_prob)\nprint(f\"\\nROC AUC score: {auc_score:.4f}\")\n\nfpr, tpr, _ = roc_curve(yTest, yPred_prob)\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Chance')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate (Recall)')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.show()\n\n# Tabel crosstab\nyTest_category = df.loc[yTest.index]['traffic_category']\nevaluasi_detail = pd.crosstab(yTest_category, yPred_binary)\nprint(f\"\\nHasil evaluasi per jenis serangan:\\n{evaluasi_detail}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Asumsikan Anda sudah melatih model multi-kelas:\n# mc_model.fit(X_train_scaled, y_train_multiclass)\n\n# 1. Buat Prediksi Multi-Kelas\n# Hasilnya akan berupa ['Benign', 'Probing', 'Bruteforce'], dll.\nyPred = rf_model.predict(xTest_scaled)\n\n# 2. Tampilkan Laporan Klasifikasi\n# Laporan ini akan otomatis menampilkan metrik untuk setiap kategori\nprint(\"--- Laporan Klasifikasi Multi-Kelas ---\")\nprint(classification_report(yTest, yPred))\n\n# 3. Tampilkan Confusion Matrix\nprint(\"\\n--- Confusion Matrix Multi-Kelas ---\")\n# Dapatkan daftar nama kelas secara urut\nclass_names = sorted(yTest.unique())\n\ncm = confusion_matrix(yTest, yPred, labels=class_names)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=class_names, yticklabels=class_names)\nplt.title('Confusion Matrix Multi-Kelas', fontsize=16)\nplt.ylabel('Label Aktual')\nplt.xlabel('Label Prediksi')\nplt.show()\n\n# --- TAMBAHAN: TABEL CROSSTAB ---\n# Tabel crosstab\nevaluasi_detail = pd.crosstab(yTest, yPred)\nprint(f\"\\nHasil evaluasi per jenis serangan:\\n{evaluasi_detail}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cek Variabel & Export Hasil","metadata":{}},{"cell_type":"code","source":"import joblib\n%whos\n\n# Menyimpan setiap variabel ke file CSV terpisah\n# x.to_csv('x_data.csv', index=False)\n# y.to_csv('y_data.csv', index=False)\nxTest_selected.to_csv('xTest.csv', index=False)\n# sampel_terfilter.to_csv('sample.csv', index=False)\n# xTrain.to_csv('xTrain_data.csv', index=False)\n# yTest.to_csv('yTest_data.csv', index=False)\n# yTrain.to_csv('yTrain_data.csv', index=False)\n# joblib.dump(scaler, 'scaler.joblib')\n# joblib.dump(rf_model, 'ult_model.joblib')\n# joblib.dump(xTest_selected, 'xTest_selected.joblib')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\nfeature_list = df.columns.tolist()\n\n# 2. Ubah list menjadi DataFrame Pandas\n# Kita beri nama kolomnya 'Nama Fitur'\ndf_features = pd.DataFrame(feature_list, columns=['Nama Fitur'])\n\nfilename = 'hikari2021_features.xlsx'\n\n# Export DataFrame ke file Excel\ndf_features.to_excel(filename, index=False)\n\n# 5. Beri konfirmasi bahwa file telah dibuat\nprint(f\"File '{filename}' berhasil dibuat!\")\nprint(f\"Total fitur yang diekspor: {len(feature_list)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}